# Understanding Messages in LangChain

[LangChain Docs - Messages](https://docs.langchain.com/oss/python/langchain/messages)

In LangChain, **Messages** are the fundamental data structure for interacting with language models. They organize the flow of a conversation, providing the necessary context for the model to understand and respond appropriately.

Every message object is composed of three key parts:

  * **Role**: Who is sending the message (e.g., the system, the user, or the AI).
  * **Content**: The actual information being conveyed, which can be text, images, or other data.
  * **Metadata**: Optional extra information, like message IDs or token usage statistics.

LangChain uses a standardized message format, which allows you to switch between different model providers without having to change your code.

### Basic Usage

You typically interact with a model by passing it a list of message objects.

```python
from langchain.chat_models import init_chat_model
from langchain.messages import HumanMessage, SystemMessage

# Initialize a chat model
model = init_chat_model("openai:gpt-4o")

# Create a list of messages to start a conversation
messages = [
    SystemMessage("You are a customer support agent for the company 'Gadgetron'."),
    HumanMessage("Hello, I have a question about my recent order.")
]

# Pass the messages to the model to get a response
response = model.invoke(messages) # This returns an AIMessage object
print(response.content)
```

#### Text vs. Message Prompts

You can pass input to a model in a few different ways, each suited for different scenarios.

  * **Text Prompts (Strings)**: Best for simple, one-off tasks where conversation history is not needed. LangChain treats a simple string as a `HumanMessage`.

    ```python
    response = model.invoke("What are your return policies?")
    ```

  * **Message Prompts (Objects)**: Essential for managing conversations, setting system behaviors, and handling complex inputs like images.

    ```python
    from langchain.messages import AIMessage

    conversation_history = [
        SystemMessage("You are a helpful customer support agent."),
        HumanMessage("I'd like to check my order status."),
        AIMessage("Certainly, what is your order number?"),
        HumanMessage("My order number is 12345.")
    ]
    response = model.invoke(conversation_history)
    ```

  * **Dictionary Format**: You can also use the standard dictionary format, which is useful for compatibility with certain APIs.

    ```python
    messages_as_dicts = [
        {"role": "system", "content": "You are a helpful customer support agent."},
        {"role": "user", "content": "I'd like to check my order status."}
    ]
    response = model.invoke(messages_as_dicts)
    ```

### Message Types

LangChain defines four primary message types to structure conversations.

#### System Message

A `SystemMessage` sets the context and instructions for the AI. It defines the AI's persona, rules, and objectives for the entire conversation. It is typically the first message in a sequence.

```python
from langchain.messages import SystemMessage

# Define the chatbot's persona and rules
system_instructions = SystemMessage("""
You are a support agent for Gadgetron.
Your tone should be helpful, professional, and patient.
Do not offer discounts unless the customer's product is damaged.
If you cannot answer a question, offer to escalate to a human agent.
""")
```

#### Human Message

A `HumanMessage` represents input from the end-user. This is what the customer types into the chat. The content can be simple text or include multimodal data like images.

```python
from langchain.messages import HumanMessage

# A simple text query from a user
user_query = HumanMessage("Where can I find the tracking number for my shipment?")

# A query with additional metadata
user_query_with_metadata = HumanMessage(
    content="My headphones arrived damaged.",
    name="customer_jane_doe", # Optional name to identify the user
    id="chat_session_987" # Optional unique ID for logging
)
```

#### AI Message

An `AIMessage` is a response generated by the model. When you call `model.invoke()`, the output is an `AIMessage` object, which contains the text response as well as any tool calls or metadata from the provider. You can also create them manually to construct a conversation history.

```python
from langchain.messages import AIMessage

# An AIMessage is returned by the model
response = model.invoke("Hello, I need help with my order.")
# response is an AIMessage object

# You can also create one manually to build a conversation history
manual_ai_response = AIMessage("I can certainly help with that. What is your order number?")
```

#### Tool Message

When a model decides to use a tool (e.g., to look up an order in a database), it generates a tool call within its `AIMessage`. After your code executes that tool, you pass the result back to the model using a `ToolMessage`. This message must include the result and the unique `tool_call_id` from the `AIMessage` so the model knows which call the result corresponds to.

```python
from langchain.messages import ToolMessage

# Assume the model's response (an AIMessage) contained this tool_call:
# {'name': 'lookup_order', 'args': {'order_id': '12345'}, 'id': 'call_abc'}

# After executing the tool, you create a ToolMessage with the result
order_status_result = "Your order #12345 has been shipped and is scheduled for delivery tomorrow."

tool_result_message = ToolMessage(
    content=order_status_result,
    tool_call_id="call_abc" # This ID must match the one from the AIMessage
)

# You would then continue the conversation, including the tool_result_message
```

### Message Content

A message's `content` is its payload. While it can be a simple string, it can also be a list of "content blocks" to support complex, multimodal data. This allows you to send text and images in the same message.

```python
from langchain.messages import HumanMessage

# A user sends a message with both text and an image of a damaged product
multimodal_message = HumanMessage(content=[
    {"type": "text", "text": "My new speaker has a crack in the casing. Can I get a replacement?"},
    {
        "type": "image_url",
        "image_url": {"url": "data:image/jpeg;base64,/9j/4AAQSk..."}, # base64 encoded image
    },
])

# The model can then process both the text and the image
response = model.invoke([multimodal_message])
```

This standardized structure for content allows LangChain to handle complex inputs consistently across different model providers, whether you're sending images, audio files, or documents.